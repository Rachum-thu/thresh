[
  {
    "_id": "47327",
    "text": "Going Beyond AER: An Extensive Analysis of Word Alignments and Their Impact on MT: This paper presents an extensive evaluation of five different alignments and investigates their impact on the corresponding MT system output. We introduce new measures for intrinsic evaluations and examine the distribution of phrases and untranslated words during decoding to identify which characteristics of different alignments affect translation. We show that precision-oriented alignments yield better MT output (translating more words and using longer phrases) than recalloriented alignments.",
    "coarse_grained_category": "Computational Linguistics",
    "fine_grained_category": "Machine Translation (MT) and Alignment Analysis",
    "sections": [
      "Background, Motivation, and Research Objectives",
      "Overview of Alignment Methods and Their Role in MT",
      "Alignment Models, Evaluation Metrics, and Data Preparation",
      "Measuring Alignment Quality and Its Direct Impact",
      "How Alignment Characteristics Influence Translation Output",
      "Impact of Alignment Strategies on MT Performance"
    ],
    "keywords": [
      "word alignment",
      "machine translation",
      "alignment evaluation",
      "intrinsic evaluation",
      "precision oriented alignments",
      "recall oriented alignments",
      "phrase distribution",
      "untranslated words",
      "decoding process",
      "translation quality",
      "alignment impact",
      "translation system performance",
      "alignment characteristics",
      "phrase length",
      "translation accuracy",
      "alignment models",
      "language pair analysis",
      "evaluation frameworks",
      "translation efficiency",
      "natural language processing"
    ]
  },
  {
    "_id": "26122",
    "text": "Automatic Features for Essay Scoring -An Empirical Study: Essay scoring is a complicated processing requiring analyzing, summarizing and judging expertise. Traditional work on essay scoring focused on automatic handcrafted features, which are expensive yet sparse. Neural models offer a way to learn syntactic and semantic features automatically, which can potentially improve upon discrete features. In this paper, we employ convolutional neural network (CNN) for the effect of automatically learning features, and compare the result with the state-of-art discrete baselines. For in-domain and domain-adaptation essay scoring tasks, our neural model empirically outperforms discrete models.",
    "coarse_grained_category": "Artificial Intelligence and Machine Learning",
    "fine_grained_category": "Natural Language Processing (NLP) and Automated Assessment Systems",
    "sections": [
      "The Complexity of Essay Scoring and the Need for Automation",
      "Traditional Approaches and Their Limitations",
      "Convolutional Neural Networks for Automatic Feature Learning",
      "Datasets, Baselines, and Evaluation Metrics",
      "Performance Comparison and Domain Adaptation Insights",
      "Implications and Directions for Future Research"
    ],
    "keywords": [
      "Essay Scoring",
      "Automatic Features",
      "Neural Models",
      "Convolutional Neural Networks",
      "Feature Learning",
      "Syntactic Features",
      "Semantic Features",
      "Discrete Features",
      "Handcrafted Features",
      "Domain Adaptation",
      "In-Domain Tasks",
      "State-of-the-Art Baselines",
      "Empirical Evaluation",
      "Automated Assessment",
      "Natural Language Processing",
      "Machine Learning",
      "Text Analysis",
      "Expert Judgment",
      "Feature Extraction",
      "Model Performance"
    ]
  },
  {
    "_id": "26262",
    "text": "Briefly Noted Syntax and Parsing: Cambridge University Press (Cambridge Studies in Linguistics, edited by Joan Bresnan et al., volume 76), 1995, xi+170 pp; hardbound, ISBN 0-521-45282-1, $44.95",
    "coarse_grained_category": "academic publishing",
    "fine_grained_category": "linguistics",
    "sections": [
      "Introduction to Syntax and Parsing",
      "Theoretical Frameworks in Syntax",
      "Parsing Mechanisms and Computational Models",
      "Empirical Studies in Syntax and Parsing",
      "Cross-Linguistic Perspectives",
      "Applications of Syntax and Parsing",
      "Critical Evaluation and Future Directions"
    ],
    "keywords": [
      "Syntax",
      "Parsing",
      "Cambridge University Press",
      "Cambridge Studies in Linguistics",
      "Joan Bresnan",
      "Volume 76",
      "Linguistics",
      "Formal Language Theory",
      "Natural Language Processing",
      "Computational Linguistics",
      "Syntax Analysis",
      "Phrase Structure Grammar",
      "Tree Structures",
      "Parsing Algorithms",
      "Lexical Analysis",
      "Semantic Parsing",
      "Language Processing",
      "Formal Syntax",
      "Language Acquisition",
      "Cognitive Linguistics"
    ]
  },
  {
    "_id": "17102",
    "text": "An Annotation Type System for a Data-Driven NLP Pipeline: We introduce an annotation type system for a data-driven NLP core system. The specifications cover formal document structure and document meta information, as well as the linguistic levels of morphology, syntax and semantics. The type system is embedded in the framework of the Unstructured Information Management Architecture (UIMA).",
    "coarse_grained_category": "Natural Language Processing (NLP)",
    "fine_grained_category": "NLP Frameworks and Architectures",
    "sections": [
      "Introduction to the Annotation Type System",
      "Overview of the UIMA Framework",
      "Formal Document Structure and Metadata Specifications",
      "Linguistic Levels: Morphology, Syntax, and Semantics",
      "Design and Implementation of the Annotation Type System",
      "Applications and Use Cases in Data-Driven NLP Pipelines"
    ],
    "keywords": [
      "Annotation Type System",
      "Data-Driven NLP Pipeline",
      "Unstructured Information Management Architecture",
      "Formal Document Structure",
      "Document Meta Information",
      "Linguistic Levels",
      "Morphology",
      "Syntax",
      "Semantics",
      "NLP Core System",
      "Type System Framework",
      "Information Management",
      "Natural Language Processing",
      "Data-Driven Systems",
      "Document Annotation",
      "Linguistic Annotation",
      "Computational Linguistics",
      "Information Architecture",
      "Semantic Annotation",
      "Structural Analysis"
    ]
  },
  {
    "_id": "12292",
    "text": "Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data: One of the main obstacles to producing high quality joint models is the lack of jointly annotated data. Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still underperforms compared to single-task models learned on the more abundant quantities of available single-task annotated data. In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model. Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model. Experiments on joint parsing and named entity recognition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data.",
    "coarse_grained_category": "Natural Language Processing (NLP)",
    "fine_grained_category": "Multitask Learning and Joint Modeling",
    "sections": [
      "The Challenge of Joint Modeling in NLP",
      "Why Joint Models Are Important and Why They Fall Short",
      "The Gap Between Joint and Single-Task Performance",
      "Integrating Single-Task and Joint Models with a Hierarchical Prior",
      "Evaluating the Hierarchical Joint Model on Joint Parsing and NER",
      "Implications and Directions for Future Research"
    ],
    "keywords": [
      "Joint Modeling",
      "Named Entity Recognition",
      "Joint Parsing",
      "Hierarchical Joint Learning",
      "Non-Jointly Labeled Data",
      "Single-Task Models",
      "Feature Weights",
      "Shared Features",
      "OntoNotes Corpus",
      "Model Performance",
      "Natural Language Processing",
      "Hierarchical Prior",
      "Data Abundance",
      "Annotation Quality",
      "Model Training",
      "Task Integration",
      "Cross-Task Learning",
      "Model Generalization",
      "Jointly Annotated Data",
      "Language Understanding"
    ]
  },
  {
    "_id": "8890",
    "text": "OntoNotes: The 90% Solution: We describe the OntoNotes methodology and its result, a large multilingual richly-annotated corpus constructed at 90% interannotator agreement. An initial portion (300K words of English newswire and 250K words of Chinese newswire) will be made available to the community during 2007.",
    "coarse_grained_category": "Natural Language Processing (NLP)",
    "fine_grained_category": "Corpus Development and Annotation",
    "sections": [
      "Introduction to OntoNotes",
      "Methodology Overview",
      "Corpus Construction and Annotation",
      "Achieving High Interannotator Agreement",
      "Content and Scope of the Corpus",
      "Availability and Community Access"
    ],
    "keywords": [
      "OntoNotes",
      "Multilingual Corpus",
      "Richly-Annotated Corpus",
      "Interannotator Agreement",
      "90% Agreement",
      "Natural Language Processing",
      "Corpus Construction",
      "Newswire Text",
      "English Newswire",
      "Chinese Newswire",
      "Annotation Methodology",
      "Community Access",
      "Open Access",
      "Linguistic Annotation",
      "Text Corpora",
      "Language Resources",
      "Machine Learning",
      "Information Extraction",
      "Semantic Annotation",
      "Cross-Lingual Research"
    ]
  },
  {
    "_id": "37466",
    "text": "Incorporating topic information into sentiment analysis models: This paper reports experiments in classifying texts based upon their favorability towards the subject of the text using a feature set enriched with topic information on a small dataset of music reviews hand-annotated for topic. The results of these experiments suggest ways in which incorporating topic information into such models may yield improvement over models which do not use topic information.",
    "coarse_grained_category": "Natural Language Processing (NLP)",
    "fine_grained_category": "Sentiment Analysis",
    "sections": [
      "Problem of Sentiment Analysis in Music Reviews",
      "Sentiment Analysis Techniques and Topic Integration Review",
      "Music Review Dataset Overview and Annotation Process",
      "Design of Feature Set Incorporating Topic Information",
      "Experimental Methodology and Evaluation Framework",
      "Performance Analysis and Implications of Topic-Informed Sentiment Classification"
    ],
    "keywords": [
      "Sentiment Analysis",
      "Topic Information",
      "Feature Set Enrichment",
      "Music Reviews",
      "Text Classification",
      "Favorability",
      "Subject of Text",
      "Hand-Annotated Dataset",
      "Model Performance",
      "Topic Modeling",
      "Natural Language Processing",
      "Machine Learning Models",
      "Textual Features",
      "Semantic Analysis",
      "Domain-Specific Data",
      "Model Enhancement",
      "Textual Semantics",
      "Annotation Process",
      "Experimental Evaluation",
      "Information Integration"
    ]
  },
  {
    "_id": "32069",
    "text": "PageRank on Semantic Networks, with Application to Word Sense Disambiguation: This paper presents a new open text word sense disambiguation method that combines the use of logical inferences with PageRank-style algorithms applied on graphs extracted from natural language documents. We evaluate the accuracy of the proposed algorithm on several sense-annotated texts, and show that it consistently outperforms the accuracy of other previously proposed knowledge-based word sense disambiguation methods. We also explore and evaluate methods that combine several open-text word sense disambiguation algorithms.",
    "coarse_grained_category": "Computational Linguistics",
    "fine_grained_category": "Natural Language Processing (NLP)",
    "sections": [
      "Introduction to Word Sense Disambiguation (WSD)",
      "Overview of PageRank and Its Relevance to Semantic Networks",
      "Methodology: Combining Logical Inferences with PageRank on Semantic Graphs",
      "Implementation and Algorithm Design",
      "Evaluation Framework and Experimental Setup",
      "Results and Comparative Analysis",
      "Discussion of Findings and Implications"
    ],
    "keywords": [
      "Word Sense Disambiguation",
      "PageRank Algorithm",
      "Semantic Networks",
      "Natural Language Processing",
      "Logical Inference",
      "Graph-Based Methods",
      "Knowledge-Based WSD",
      "Open Text Corpora",
      "Sense-Annotated Texts",
      "Algorithm Evaluation",
      "Accuracy Metrics",
      "Text Mining",
      "Semantic Graphs",
      "Information Retrieval",
      "Computational Linguistics",
      "Machine Learning",
      "Text Classification",
      "Ontology Construction",
      "Language Models",
      "Disambiguation Techniques"
    ]
  },
  {
    "_id": "23802",
    "text": "The Architectural Bottleneck Principle: In this paper, we seek to measure how much information a component in a neural network could extract from the representations fed into it. Our work stands in contrast to prior probing work, most of which investigates how much information a model's representations contain. This shift in perspective leads us to propose a new principle for probing, the architectural bottleneck principle: In order to estimate how much information a given component could extract, a probe should look exactly like the component. Relying on this principle, we estimate how much syntactic information is available to transformers through our attentional probe, a probe that exactly resembles a transformer's self-attention head. Experimentally, we find that, in three models (BERT, ALBERT, and RoBERTa), a sentence's syntax tree is mostly extractable by our probe, suggesting these models have access to syntactic information while composing their contextual representations. Whether this information is actually used by these models, however, remains an open question.",
    "coarse_grained_category": "Artificial Intelligence and Machine Learning",
    "fine_grained_category": "Natural Language Processing (NLP)",
    "sections": [
      "Introduction to the Architectural Bottleneck Principle",
      "Background and Related Work",
      "The Architectural Bottleneck Principle",
      "Methodology: Designing the Attentional Probe",
      "Experimental Setup and Results",
      "Discussion and Implications"
    ],
    "keywords": [
      "architectural bottleneck principle",
      "neural network components",
      "information extraction",
      "transformer models",
      "self-attention head",
      "syntactic information",
      "contextual representations",
      "probing methodology",
      "representation analysis",
      "model transparency",
      "information-theoretic perspective",
      "attentional probe",
      "syntax tree extraction",
      "model compositionality",
      "linguistic structure",
      "deep learning interpretability",
      "component-specific probing",
      "open research questions",
      "bert",
      "roberta"
    ]
  },
  {
    "_id": "19018",
    "text": "Annotation Compatibility Working Group Report*: This report explores the question of compatibility between annotation projects including translating annotation formalisms to each other or to common forms. Compatibility issues are crucial for systems that use the results of multiple annotation projects. We hope that this report will begin a concerted effort in the field to track the compatibility of annotation schemes for part of speech tagging, time annotation, treebanking, role labeling and other phenomena.",
    "coarse_grained_category": "Natural Language Processing (NLP)",
    "fine_grained_category": "linguistic annotation and interoperability",
    "sections": [
      "The Need for Annotation Compatibility",
      "Defining the Scope of Annotation Compatibility",
      "A Survey of Existing Annotation Schemes",
      "Barriers to Interoperable Annotation",
      "Approaches to Improve Annotation Interoperability",
      "Toward a Unified Framework for Annotation Compatibility"
    ],
    "keywords": [
      "Annotation Compatibility",
      "Annotation Projects",
      "Annotation Formalisms",
      "Translation of Annotation Schemes",
      "Common Annotation Forms",
      "Interoperability",
      "Annotation Systems",
      "Part-of-Speech Tagging",
      "Time Annotation",
      "Treebanking",
      "Role Labeling",
      "Annotation Schemes",
      "Cross-Project Compatibility",
      "Standardization of Annotations",
      "Data Integration",
      "Multilingual Annotation",
      "Natural Language Processing",
      "Linguistic Annotation",
      "Annotation Frameworks",
      "Collaborative Annotation Efforts"
    ]
  },
  {
    "_id": "23939",
    "text": "Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback: Despite the seeming success of contemporary grounded text generation systems, they often tend to generate factually inconsistent text with respect to their input. This phenomenon is emphasized in tasks like summarization, in which the generated summaries should be corroborated by their source article. In this work we leverage recent progress on textual entailment models to directly address this problem for abstractive summarization systems. We use reinforcement learning with reference-free, textualentailment rewards to optimize for factual consistency and explore the ensuing trade-offs, as improved consistency may come at the cost of less informative or more extractive summaries. Our results, according to both automatic metrics and human evaluation, show that our method considerably improves the faithfulness, salience and conciseness of the generated summaries.",
    "coarse_grained_category": "Artificial Intelligence and Machine Learning",
    "fine_grained_category": "Natural Language Processing (NLP)",
    "sections": [
      "The Challenge of Factual Consistency in Abstractive Summarization",
      "Textual Entailment and Reinforcement Learning in NLP",
      "Reinforcement Learning with Textual Entailment Rewards",
      "Model Architecture and Training Procedure",
      "Improving Faithfulness, Salience, and Conciseness",
      "Balancing Consistency and Information Density"
    ],
    "keywords": [
      "Factually Consistent Summarization",
      "Reinforcement Learning",
      "Text Generation Systems",
      "Abstractive Summarization",
      "Textual Entailment",
      "Factual Inconsistency",
      "Reference-Free Rewards",
      "Faithfulness",
      "Salience",
      "Conciseness",
      "Automated Metrics",
      "Human Evaluation",
      "Textual Entailment Models",
      "Trade-offs in Summarization",
      "Informational Content",
      "Extractive vs Abstractive Summarization",
      "Grounded Text Generation",
      "Summarization Tasks",
      "Model Optimization",
      "Natural Language Processing",
      "Machine Learning Techniques",
      "Text Generation",
      "Factual Consistency",
      "Summarization",
      "NLP",
      "Reward Mechanisms",
      "Evaluation Methods",
      "Conceptual Themes"
    ]
  },
  {
    "_id": "28739",
    "text": "IMBERT: Making BERT Immune to Insertion-based Backdoor Attacks: Backdoor attacks are an insidious security threat against machine learning models. Adversaries can manipulate the predictions of compromised models by inserting triggers into the training phase. Various backdoor attacks have been devised which can achieve nearly perfect attack success without affecting model predictions for clean inputs. Means of mitigating such vulnerabilities are underdeveloped, especially in natural language processing. To fill this gap, we introduce IMBERT, which uses either gradients or self-attention scores derived from victim models to self-defend against backdoor attacks at inference time. Our empirical studies demonstrate that IMBERT can effectively identify up to 98.5% of inserted triggers. Thus, it significantly reduces the attack success rate while attaining competitive accuracy on the clean dataset across widespread insertion-based attacks compared to two baselines. Finally, we show that our approach is model-agnostic, and can be easily ported to several pre-trained transformer models. * Now at Google DeepMind. 1 According to statistics from Hugging Face, BERT receives 15M downloads per month.",
    "coarse_grained_category": "Artificial Intelligence and Machine Learning",
    "fine_grained_category": "Natural Language Processing (NLP) Security",
    "sections": [
      "Introduction to Backdoor Attacks in NLP",
      "Motivation and Research Gap",
      "Overview of IMBERT: A Novel Defense Mechanism",
      "Technical Framework of IMBERT",
      "Empirical Evaluation of IMBERT",
      "Model-Agnostic Design and Portability",
      "Conclusion and Future Work"
    ],
    "keywords": [
      "Backdoor Attacks",
      "BERT",
      "Insertion-based Attacks",
      "Machine Learning Security",
      "Adversarial Manipulation",
      "Trigger",
      "Model Compromise",
      "Inference Time Defense",
      "Self-Attention Scores",
      "Gradient Analysis",
      "Natural Language Processing",
      "Attack Success Rate",
      "Clean Inputs",
      "Model Agnosticism",
      "Pre-trained Transformer Models",
      "Hugging Face",
      "Security Vulnerabilities",
      "Empirical Studies",
      "Competitive Accuracy",
      "DeepMind"
    ]
  },
  {
    "_id": "18571",
    "text": "Extracting Topics from Texts Based on Situations: To understand text, we must relate it with specified situations. This paper, on the basis of such an idea, discusses how the things that a text describes and the situation that the text relates to are expressed in a computer and how the topic of a text is extracted.",
    "coarse_grained_category": "Natural Language Processing (NLP)",
    "fine_grained_category": "text analysis",
    "sections": [
      "The Role of Context in Text Understanding",
      "Situational Text Analysis Theoretical Foundations",
      "Challenges in Topic Extraction from Situational Texts",
      "Methodologies for Situational Topic Extraction",
      "Implementation and Case Studies in Situational Topic Extraction",
      "Evaluation of Situational Topic Models",
      "Future Directions in Situational Topic Extraction Research"
    ],
    "keywords": [
      "text analysis",
      "topic extraction",
      "situation based understanding",
      "textual semantics",
      "computational linguistics",
      "natural language processing",
      "contextual relevance",
      "semantic representation",
      "text classification",
      "information retrieval",
      "discourse analysis",
      "document thematic modeling",
      "machine learning for text",
      "textual contextualization",
      "situation awareness",
      "textual interpretation",
      "conceptual mapping",
      "ontology construction",
      "textual meaning generation",
      "computational text understanding"
    ]
  },
  {
    "_id": "35009",
    "text": "HyTER: Meaning-Equivalent Semantics for Translation Evaluation: It is common knowledge that translation is an ambiguous, 1-to-n mapping process, but to date, our community has produced no empirical estimates of this ambiguity. We have developed an annotation tool that enables us to create representations that compactly encode an exponential number of correct translations for a sentence. Our findings show that naturally occurring sentences have billions of translations. Having access to such large sets of meaning-equivalent translations enables us to develop a new metric, HyTER, for translation accuracy. We show that our metric provides better estimates of machine and human translation accuracy than alternative evaluation metrics.",
    "coarse_grained_category": "Computational Linguistics",
    "fine_grained_category": "Machine Translation Evaluation",
    "sections": [
      "The Ambiguity of Translation as a Core Challenge",
      "Rationale for Empirical Estimation of Translation Ambiguity",
      "Design and Functionality of the Annotation Tool",
      "Quantifying Translation Ambiguity Through Empirical Data",
      "HyTER: A Novel Metric for Translation Accuracy",
      "Comparative Evaluation of HyTER Against Existing Metrics"
    ],
    "keywords": [
      "translation evaluation",
      "meaning equivalent semantics",
      "ambiguity in translation",
      "1-to-n mapping",
      "hyter metric",
      "machine translation accuracy",
      "human translation accuracy",
      "annotation tool",
      "exponential number of translations",
      "natural language processing",
      "translation ambiguity estimation",
      "semantic representation",
      "translation metrics",
      "empirical estimates",
      "language models",
      "translation quality assessment",
      "semantic equivalence",
      "translation ambiguity",
      "linguistic analysis",
      "computational linguistics"
    ]
  },
  {
    "_id": "24670",
    "text": "AGIF: An Adaptive Graph-Interactive Framework for Joint Multiple Intent Detection and Slot Filling: In real-world scenarios, users usually have multiple intents in the same utterance. Unfortunately, most spoken language understanding (SLU) models either mainly focused on the single intent scenario, or simply incorporated an overall intent context vector for all tokens, ignoring the fine-grained multiple intents information integration for token-level slot prediction. In this paper, we propose an Adaptive Graph-Interactive Framework (AGIF) for joint multiple intent detection and slot filling, where we introduce an intent-slot graph interaction layer to model the strong correlation between the slot and intents. Such an interaction layer is applied to each token adaptively, which has the advantage to automatically extract the relevant intents information, making a fine-grained intent information integration for the token-level slot prediction. Experimental results on three multiintent datasets show that our framework obtains substantial improvement and achieves the state-of-the-art performance. In addition, our framework achieves new state-of-the-art performance on two single-intent datasets.",
    "coarse_grained_category": "Artificial Intelligence",
    "fine_grained_category": "Natural Language Processing (NLP)",
    "sections": [
      "Challenges in Multi-Intent Spoken Language Understanding",
      "Survey of Existing Approaches to Intent Detection and Slot Filling",
      "Introducing the Adaptive Graph-Interactive Framework (AGIF)",
      "Design and Components of AGIF",
      "Performance Assessment on Multi-Intent Datasets",
      "State-of-the-Art Performance on Single-Intent Tasks"
    ],
    "keywords": [
      "Adaptive Graph-Interactive Framework",
      "Multiple Intent Detection",
      "Slot Filling",
      "Spoken Language Understanding",
      "Joint Task Learning",
      "Intent-Slot Graph Interaction",
      "Token-Level Slot Prediction",
      "Fine-Grained Intent Integration",
      "Single Intent Scenario",
      "Multi-Intent Datasets",
      "State-of-the-Art Performance",
      "Graph-Based Modeling",
      "Natural Language Processing",
      "Dialogue Systems",
      "Context Vector Integration",
      "Adaptive Interaction Mechanism",
      "Intent Correlation Modeling",
      "Utterance Analysis",
      "Model Adaptability",
      "Speech Recognition",
      "Understanding",
      "NLP",
      "Dialog Systems",
      "SLU",
      "Graph Modeling",
      "Intent Detection",
      "Slot Prediction",
      "Joint Learning",
      "Context Integration",
      "Adaptive Mechanism"
    ]
  },
  {
    "_id": "4778",
    "text": "Harvey Mudd College at SemEval-2019 Task 4: The Clint Buchanan Hyperpartisan News Detector: We investigate the recently developed Bidirectional Encoder Representations from Transformers (BERT) model(Devlin et al., 2018)for the hyperpartisan news detection task. Using a subset of hand-labeled articles from Se-mEval as a validation set, we test the performance of different parameters for BERT models. We find that accuracy from two different BERT models using different proportions of the articles is consistently high, with our bestperforming model on the validation set achieving 85% accuracy and the best-performing model on the test set achieving 77%. We further determined that our model exhibits strong consistency, labeling independent slices of the same article identically. Finally, we find that randomizing the order of word pieces dramatically reduces validation accuracy (to approximately 60%), but that shuffling groups of four or more word pieces maintains an accuracy of about 80%, indicating the model mainly gains value from local context.",
    "coarse_grained_category": "Artificial Intelligence and Machine Learning",
    "fine_grained_category": "Text Classification and Sentiment Analysis",
    "sections": [
      "Introduction to the Task and Model",
      "Methodology and Experimental Setup",
      "Model Performance Evaluation",
      "Consistency of Model Predictions",
      "Impact of Word Order on Model Performance",
      "Conclusion and Implications"
    ],
    "keywords": [
      "Hyperpartisan News Detection",
      "BERT",
      "SemEval-2019",
      "Accuracy",
      "Validation Set",
      "Test Set",
      "Model Parameters",
      "Word Pieces",
      "Contextual Understanding",
      "Local Context",
      "Consistency",
      "Randomization",
      "Shuffling",
      "Tokenization",
      "NLP",
      "Machine Learning",
      "Text Classification",
      "Sentiment Analysis",
      "Information Retrieval",
      "Social Media Monitoring"
    ]
  },
  {
    "_id": "14662",
    "text": "Automatically Creating Bilingual Lexicons for Machine Translation from Bilingual Text: A method is presented for automatically augmenting the bilingual lexicon of an existing Machine Translation system, by extracting bilingual entries from aligned bilingual text. The proposed method only relies on the resources already available in the MT system itself. It is based on the use of bilingual lexical templates to match the terminal symbols in the parses of the aligned sentences.",
    "coarse_grained_category": "Computational Linguistics",
    "fine_grained_category": "Machine Translation and NLP Techniques",
    "sections": [
      "Introduction to Bilingual Lexicons in Machine Translation",
      "Overview of Existing Methods for Lexicon Augmentation",
      "Proposed Method: Automated Extraction Using Bilingual Lexical Templates",
      "Implementation Details and System Architecture",
      "Evaluation and Results",
      "Conclusion and Future Work"
    ],
    "keywords": [
      "Machine Translation",
      "Bilingual Lexicon",
      "Lexicon Augmentation",
      "Bilingual Text",
      "Aligned Sentences",
      "Parsing",
      "Terminal Symbols",
      "Bilingual Lexical Templates",
      "Automated Methods",
      "Natural Language Processing",
      "Translation Systems",
      "Language Resources",
      "Syntactic Analysis",
      "Cross-Linguistic Alignment",
      "Lexical Extraction",
      "Translation Models",
      "Semantic Mapping",
      "Resource-Driven Approaches",
      "Text Alignment",
      "Language Pairing"
    ]
  },
  {
    "_id": "36618",
    "text": "Attribute-Based and Value-Based Clustering: An Evaluation: In most research on concept acquisition from corpora, concepts are modeled as vectors of relations extracted from syntactic structures. In the case of modifiers, these relations often specify values of attributes, as in (attr red); this is unlike what typically proposed in theories of knowledge representation, where concepts are typically defined in terms of their attributes (e.g., color).We compared models of concepts based on values with models based on attributes, using lexical clustering as the basis for comparison. We find that attribute-based models work better than value-based ones, and result in shorter descriptions; but that mixed models including both the best attributes and the best values work best of all.",
    "coarse_grained_category": "Computational Linguistics",
    "fine_grained_category": "Concept Representation and Lexical Clustering",
    "sections": [
      "Introduction to Concept Acquisition from Corpora",
      "Role of Attributes and Values in Concept Representation",
      "Methodology for Comparing Clustering Models",
      "Performance Evaluation of Attribute-Based Models",
      "Superiority of Mixed Attribute-Value Models",
      "Implications for Concept Modeling and NLP"
    ],
    "keywords": [
      "Concept Acquisition",
      "Corpora",
      "Attribute-Based Clustering",
      "Value-Based Clustering",
      "Lexical Clustering",
      "Concept Modeling",
      "Syntactic Structures",
      "Modifiers",
      "Attribute Values",
      "Knowledge Representation",
      "Conceptual Definitions",
      "Color Attributes",
      "Natural Language Processing",
      "Semantic Analysis",
      "Model Evaluation",
      "Descriptive Efficiency",
      "Mixed Models",
      "Conceptual Ontology",
      "Lexical Semantics",
      "Information Retrieval"
    ]
  },
  {
    "_id": "15957",
    "text": "Improving Entity Linking using Surface Form Refinement: In this paper, we present an algorithm for improving named entity resolution and entity linking by using surface form generation and rewriting. Surface forms consist of a word or a group of words that matches lexical units like Paris or New York City. Used as matching sequences to select candidate entries in a knowledge base, they contribute to the disambiguation of those candidates through similarity measures. In this context, misspelled textual sequences (entities) can be impossible to identify due to the lack of available matching surface forms. To address this problem, we propose an algorithm for surface form refinement based on Wikipedia resources. The approach extends the surface form coverage of our entity linking system, and rewrites or reformulates misspelled mentions (entities) prior to starting the annotation process. The algorithm is evaluated on the corpus associated with the monolingual English entity linking task of NIST KBP 2013. We show that the algorithm improves the entity linking system performance.",
    "coarse_grained_category": "Natural Language Processing (NLP)",
    "fine_grained_category": "Entity Linking and Resolution",
    "sections": [
      "Introduction to Entity Linking and Surface Forms",
      "Challenges in Entity Linking Due to Misspelled Surface Forms",
      "Proposed Algorithm: Surface Form Refinement",
      "How Surface Form Refinement Works in Practice",
      "Experimental Setup and Performance Analysis",
      "Implications and Directions for Further Research"
    ],
    "keywords": [
      "Entity Linking",
      "Named Entity Resolution",
      "Surface Form Generation",
      "Surface Form Rewriting",
      "Lexical Units",
      "Knowledge Base Matching",
      "Disambiguation",
      "Similarity Measures",
      "Misspelled Entities",
      "Surface Form Coverage",
      "Algorithm Development",
      "Wikipedia Resources",
      "Entity Annotation Process",
      "NIST KBP 2013 Corpus",
      "Monolingual Entity Linking",
      "Textual Discrepancy Handling",
      "Natural Language Processing",
      "Information Retrieval",
      "Semantic Disambiguation",
      "Machine Learning for NER"
    ]
  },
  {
    "_id": "11159",
    "text": "A best-first alignment algorithm for automatic extraction of transfer mappings from bilingual corpora: Translation systems that automatically extract transfer mappings (rules or examples) from bilingual corpora have been hampered by the difficulty of achieving accurate alignment and acquiring high quality mappings. We describe an algorithm that uses a bestfirst strategy and a small alignment grammar to significantly improve the quality of the transfer mappings extracted.For each mapping, frequencies are computed and sufficient context is retained to distinguish competing mappings during translation. Variants of the algorithm are run against a corpus containing 200K sentence pairs and evaluated based on the quality of resulting translations.",
    "coarse_grained_category": "Computational Linguistics",
    "fine_grained_category": "Machine Translation",
    "sections": [
      "Challenges in Automatic Transfer Mapping Extraction",
      "Best-First Strategy with Alignment Grammar",
      "Mechanisms for Frequency Computation and Context Retention",
      "Assessment of Translation Quality",
      "Corpus Details and Baseline Comparisons",
      "Performance Evaluation and Quality Improvements",
      "Impacts on Transfer Learning and NLP Applications",
      "Summary and Future Work"
    ],
    "keywords": [
      "best first alignment",
      "transfer mappings",
      "bilingual corpora",
      "automatic extraction",
      "translation systems",
      "alignment accuracy",
      "mapping quality",
      "small alignment grammar",
      "context retention",
      "competing mappings",
      "frequency computation",
      "translation quality evaluation",
      "corpus size",
      "algorithm variants",
      "natural language processing",
      "machine translation",
      "rule based systems",
      "example based learning",
      "language modeling",
      "computational linguistics"
    ]
  }
]